import os
from typing import List

import numpy as np
from PIL import Image
import torch
import math
from torch.utils.data import IterableDataset
import pandas as pd

from .label import get_cs_trainId


class SampleBasedDataset(IterableDataset):

    def __init__(self, prob, *args, **kwargs) -> None:
        # list of list, or list of datasets
        self.data_lists = self.get_data()
        # for data_list in self.data_lists:
        #     assert len(data_list) != 0

        # probabilities of sampling from items in self.data_lists
        self.prob = prob
        assert len(self.prob) == len(self.data_lists)

    def get_data(self, *args, **kwargs):
        raise NotImplementedError

    def load_data(self, cate, idx):
        raise NotImplementedError

    class SampleBasedDatasetIterator:

        def __init__(self, data_lists, prob, outer_load_data, idx=0, total=1) -> None:
            self.data_lists = data_lists
            self.idx = idx
            self.total = total
            self.prob = prob
            self.load_data = outer_load_data

        def __next__(self):
            cate = np.random.choice(len(self.data_lists), p=self.prob)
            step = math.ceil(len(self.data_lists[cate]) / self.total)
            start = self.idx * step
            end = min(len(self.data_lists[cate]), (self.idx + 1) * step)
            idx = np.random.choice(range(start, end))
            return self.load_data(cate, idx)

    def __iter__(self):
        worker_info = torch.utils.data.get_worker_info()
        return self.SampleBasedDatasetIterator(self.data_lists, self.prob, self.load_data, worker_info.id, worker_info.num_workers)


class BlendedDataset(SampleBasedDataset):

    def __init__(self, prob, *args, **kwargs) -> None:
        self.datasets = args
        super().__init__(prob, *args, **kwargs)

    def get_data(self):
        return self.datasets  # Suppose args is a list of torch.utils.data.Dataset

    def load_data(self, cate, idx):
        # print(cate)
        return self.data_lists[cate][idx]


class SampledCarlaDataset(SampleBasedDataset):

    def __init__(self, dataset_root, split, stat_file, sum_file, custom_mask=None, transform=None, *args, **kwargs) -> None:
        # stat_file and sum_file are generated by gen_stat.py

        self.dataset_root = dataset_root
        self.split = split

        self.stats = np.load(stat_file, allow_pickle=True)
        freqs = np.load(sum_file)
        mask = freqs != 0
        self.p = np.zeros_like(freqs)
        self.p[mask] = freqs[mask].sum() / freqs[mask]
        if custom_mask:
            custom_mask = np.load(custom_mask)
            self.p[custom_mask == False] = 0
        self.p = self.p / self.p.sum()

        self.transform = transform

        classes = get_cs_trainId(None)
        self.id2trainId = np.array([c.train_id for c in classes])
        self.trainId2color = np.array([c.color for c in classes if (c.train_id != -1 and c.train_id != 255)] + [[0, 0, 0]])

        super().__init__(self.p, *args, **kwargs)

    @classmethod
    def create_df(cls, data_dir, split, name_list):
        if split == 'both':
            _split = 'train'
            data_list = sorted([os.path.join(data_dir, _split, "rgb", f"{i}_rgb.png") for i in name_list])
            label_list = sorted([os.path.join(data_dir, _split, "semantic", f"{i}_semantic.png") for i in name_list])
            _split = 'val'
            data_list = sorted([os.path.join(data_dir, _split, "rgb", f"{i}_rgb.png") for i in name_list])
            label_list = sorted([os.path.join(data_dir, _split, "semantic", f"{i}_semantic.png") for i in name_list])
        else:
            assert split in ['train', 'val']
            data_list = sorted([os.path.join(data_dir, split, "rgb", f"{i}_rgb.png") for i in name_list])
            label_list = sorted([os.path.join(data_dir, split, "semantic", f"{i}_semantic.png") for i in name_list])

        return pd.DataFrame(dict(data_path=data_list, label_path=label_list))

    def get_data(self):
        return [self.create_df(self.dataset_root, self.split, name_list) for name_list in self.stats]

    def _encode_target(self, target):
        return self.id2trainId[np.array(target)]

    def _decode_target(self, target):
        target[target == 255] = 19
        return self.train_id_to_color[target]

    def load_data(self, cate, idx):
        image = Image.open(self.data_lists[cate].data_path[idx])
        target = Image.open(self.data_lists[cate].label_path[idx])
        if self.transform is not None:
            image, target = self.transform(image, target)
        target = self._encode_target(target)
        return image, target


class SampledCarlaMaskDataset(SampledCarlaDataset):

    def load_data(self, cate, idx):
        image, target = super().load_data(cate, idx)
        target[target != cate] = 255
        return image, target